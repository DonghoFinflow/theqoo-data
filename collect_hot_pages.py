#!/usr/bin/env python3
"""
Hot ê²Œì‹œíŒ 2~10í˜ì´ì§€ ë°ì´í„° ìˆ˜ì§‘ ìŠ¤í¬ë¦½íŠ¸
í…ŒìŠ¤íŠ¸ìš© ë¬¸ì„œ ìƒì„±ì„ ìœ„í•œ ë°ì´í„° ìˆ˜ì§‘
"""

import logging
import json
import time
from datetime import datetime
from main_workflow import TheqooWorkflow

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

def collect_hot_pages_data():
    """Hot ê²Œì‹œíŒ 2~10í˜ì´ì§€ ë°ì´í„° ìˆ˜ì§‘"""
    
    print("=== Hot ê²Œì‹œíŒ 2~10í˜ì´ì§€ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘ ===")
    
    try:
        # ì›Œí¬í”Œë¡œìš° ì´ˆê¸°í™”
        workflow = TheqooWorkflow()
        
        all_titles = []
        current_date = datetime.now().strftime("%Y-%m-%d")
        
        # 2~10í˜ì´ì§€ ìˆœíšŒ
        for page_num in range(2, 11):
            print(f"\nğŸ“„ í˜ì´ì§€ {page_num} ìˆ˜ì§‘ ì¤‘...")
            
            try:
                # ê° í˜ì´ì§€ì—ì„œ ëª¨ë“  ì œëª© ìˆ˜ì§‘ (start_idx=0, end_idx=20ìœ¼ë¡œ ì„¤ì •í•˜ì—¬ ëª¨ë“  ì œëª© ê°€ì ¸ì˜¤ê¸°)
                titles = workflow.get_hot_titles(page_num=page_num, start_idx=0, end_idx=20)
                
                if not titles:
                    print(f"âš ï¸ í˜ì´ì§€ {page_num}ì—ì„œ ì œëª©ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                    continue
                
                # í˜ì´ì§€ ì •ë³´ ì¶”ê°€
                for title in titles:
                    title['page_num'] = page_num
                    title['collected_date'] = current_date
                
                all_titles.extend(titles)
                print(f"âœ… í˜ì´ì§€ {page_num}: {len(titles)}ê°œ ì œëª© ìˆ˜ì§‘ ì™„ë£Œ")
                
                # í˜ì´ì§€ ê°„ ê°„ê²© ì¡°ì ˆ (ì„œë²„ ë¶€í•˜ ë°©ì§€)
                time.sleep(3)
                
            except Exception as e:
                logger.error(f"í˜ì´ì§€ {page_num} ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
                print(f"âŒ í˜ì´ì§€ {page_num} ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
                continue
        
        # ê²°ê³¼ ì¶œë ¥
        print(f"\n=== ìˆ˜ì§‘ ì™„ë£Œ ===")
        print(f"ì´ ìˆ˜ì§‘ëœ ì œëª© ìˆ˜: {len(all_titles)}")
        
        # í˜ì´ì§€ë³„ í†µê³„
        page_stats = {}
        for title in all_titles:
            page_num = title['page_num']
            if page_num not in page_stats:
                page_stats[page_num] = 0
            page_stats[page_num] += 1
        
        print("\nğŸ“Š í˜ì´ì§€ë³„ ìˆ˜ì§‘ í˜„í™©:")
        for page_num in sorted(page_stats.keys()):
            print(f"  í˜ì´ì§€ {page_num}: {page_stats[page_num]}ê°œ")
        
        # JSON íŒŒì¼ë¡œ ì €ì¥
        filename = f"hot_pages_2_10_{current_date}.json"
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(all_titles, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ’¾ ë°ì´í„°ê°€ {filename}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        # ìƒ˜í”Œ ë°ì´í„° ì¶œë ¥
        if all_titles:
            print("\n=== ìƒ˜í”Œ ë°ì´í„° ===")
            sample = all_titles[0]
            print(f"ì œëª©: {sample['title']}")
            print(f"ë§í¬: {sample['link']}")
            print(f"í˜ì´ì§€: {sample['page_num']}")
            print(f"ìˆ˜ì§‘ì¼: {sample['collected_date']}")
        
        return True, all_titles
        
    except Exception as e:
        logger.error(f"ë°ì´í„° ìˆ˜ì§‘ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        print(f"âŒ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
        return False, []

def create_test_documents(titles_data, max_documents=50):
    """ìˆ˜ì§‘ëœ ì œëª© ë°ì´í„°ë¡œ í…ŒìŠ¤íŠ¸ìš© ë¬¸ì„œ ìƒì„±"""
    
    print(f"\n=== í…ŒìŠ¤íŠ¸ìš© ë¬¸ì„œ ìƒì„± ì‹œì‘ (ìµœëŒ€ {max_documents}ê°œ) ===")
    
    try:
        workflow = TheqooWorkflow()
        documents = []
        current_date = datetime.now().strftime("%Y-%m-%d")
        
        # ì œëª© ë¶„ë¥˜
        print("1ë‹¨ê³„: ì œëª© ë¶„ë¥˜ ì¤‘...")
        classified_titles = workflow.classify_titles(titles_data[:max_documents])
        
        if not classified_titles:
            print("âŒ ì œëª© ë¶„ë¥˜ ì‹¤íŒ¨")
            return False, []
        
        print(f"âœ… {len(classified_titles)}ê°œ ì œëª© ë¶„ë¥˜ ì™„ë£Œ")
        
        # ì´ìŠˆë¡œ ë¶„ë¥˜ëœ ì œëª©ë§Œ í•„í„°ë§
        issue_titles = [item for item in classified_titles if item.get("is_issue") == "Y"]
        print(f"âœ… ì´ìŠˆë¡œ ë¶„ë¥˜ëœ ì œëª©: {len(issue_titles)}ê°œ")
        
        if not issue_titles:
            print("âš ï¸ ì´ìŠˆë¡œ ë¶„ë¥˜ëœ ì œëª©ì´ ì—†ìŠµë‹ˆë‹¤. ëª¨ë“  ì œëª©ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤.")
            issue_titles = classified_titles
        
        # ê° ì´ìŠˆì— ëŒ€í•´ ìƒì„¸ ì •ë³´ ìˆ˜ì§‘
        print(f"\n2ë‹¨ê³„: ìƒì„¸ ì •ë³´ ìˆ˜ì§‘ (ìµœëŒ€ {min(max_documents, len(issue_titles))}ê°œ)...")
        
        for idx, item in enumerate(issue_titles[:max_documents], 1):
            print(f"\n--- ì²˜ë¦¬ ì¤‘: {idx}/{min(max_documents, len(issue_titles))} ---")
            print(f"ì œëª©: {item['title'][:50]}...")
            
            try:
                # ì‘ì„±ì¼ì‹œ ì¶”ì¶œ
                print("  - ì‘ì„±ì¼ì‹œ ì¶”ì¶œ ì¤‘...")
                post_datetime = workflow.get_post_datetime(item['link'])
                print(f"    ì‘ì„±ì¼ì‹œ: {post_datetime}")
                
                # ê²Œì‹œê¸€ ë‚´ìš©ê³¼ ëŒ“ê¸€ ìˆ˜ì§‘
                print("  - ê²Œì‹œê¸€ ë‚´ìš© ë° ëŒ“ê¸€ ìˆ˜ì§‘ ì¤‘...")
                post_data = workflow.get_post_content_and_comments(item['link'], max_comments=20)
                print(f"    ëŒ“ê¸€ ìˆ˜: {len(post_data['comments'])}ê°œ")
                
                # Perplexity ë¶„ì„
                print("  - Perplexity ë¶„ì„ ì¤‘...")
                analysis = workflow.analyze_with_perplexity(
                    item['title'], 
                    post_data['content'], 
                    post_data['comments']
                )
                print(f"    ë¶„ì„ ì™„ë£Œ (ê¸¸ì´: {len(analysis)} ë¬¸ì)")
                
                # ë¬¸ì„œ ìƒì„±
                document = {
                    "title": item['title'],
                    "link": item['link'],
                    "page_num": item.get('page_num', 'unknown'),
                    "post_datetime": post_datetime,
                    "content": post_data['content'],
                    "comments": post_data['comments'],
                    "comments_count": len(post_data['comments']),
                    "analysis": analysis,
                    "collected_date": current_date,
                    "id": f"theqoo_{current_date}_{idx}"
                }
                
                documents.append(document)
                print(f"  âœ… ë¬¸ì„œ ìƒì„± ì™„ë£Œ: {document['id']}")
                
                # API í˜¸ì¶œ ê°„ê²© ì¡°ì ˆ
                time.sleep(2)
                
            except Exception as e:
                logger.error(f"ë¬¸ì„œ ì²˜ë¦¬ ì‹¤íŒ¨: {e}")
                print(f"  âŒ ì˜¤ë¥˜: {e}")
                continue
        
        # ê²°ê³¼ ì¶œë ¥
        print(f"\n=== ë¬¸ì„œ ìƒì„± ì™„ë£Œ ===")
        print(f"ìƒì„±ëœ ë¬¸ì„œ ìˆ˜: {len(documents)}")
        
        if documents:
            # JSON íŒŒì¼ë¡œ ì €ì¥
            filename = f"test_documents_hot_pages_{current_date}.json"
            with open(filename, 'w', encoding='utf-8') as f:
                json.dump(documents, f, ensure_ascii=False, indent=2)
            print(f"\në¬¸ì„œê°€ {filename}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
            
            # ìƒ˜í”Œ ë¬¸ì„œ ì¶œë ¥
            print("\n=== ìƒ˜í”Œ ë¬¸ì„œ ===")
            sample = documents[0]
            print(f"ì œëª©: {sample['title']}")
            print(f"ë§í¬: {sample['link']}")
            print(f"í˜ì´ì§€: {sample['page_num']}")
            print(f"ì‘ì„±ì¼ì‹œ: {sample['post_datetime']}")
            print(f"ëŒ“ê¸€ ìˆ˜: {sample['comments_count']}")
            print(f"ë¶„ì„ ê¸¸ì´: {len(sample['analysis'])} ë¬¸ì")
            print(f"ë¶„ì„ ë¯¸ë¦¬ë³´ê¸°: {sample['analysis'][:100]}...")
        
        return True, documents
        
    except Exception as e:
        logger.error(f"ë¬¸ì„œ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        print(f"âŒ ë¬¸ì„œ ìƒì„± ì‹¤íŒ¨: {e}")
        return False, []

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("Hot ê²Œì‹œíŒ 2~10í˜ì´ì§€ ë°ì´í„° ìˆ˜ì§‘ì„ ì‹œì‘í•©ë‹ˆë‹¤...")
    print("ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” í…ŒìŠ¤íŠ¸ìš© ë¬¸ì„œ ìƒì„±ì„ ìœ„í•œ ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.\n")
    
    # 1ë‹¨ê³„: ë°ì´í„° ìˆ˜ì§‘
    success, titles_data = collect_hot_pages_data()
    
    if not success or not titles_data:
        print("\nğŸ’¥ ë°ì´í„° ìˆ˜ì§‘ ì‹¤íŒ¨!")
        return
    
    # 2ë‹¨ê³„: í…ŒìŠ¤íŠ¸ìš© ë¬¸ì„œ ìƒì„± (ì„ íƒì‚¬í•­)
    print(f"\nìˆ˜ì§‘ëœ ë°ì´í„°ë¡œ í…ŒìŠ¤íŠ¸ìš© ë¬¸ì„œë¥¼ ìƒì„±í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ", end="")
    user_input = input().strip().lower()
    
    if user_input in ['y', 'yes', 'ã…‡']:
        doc_success, documents = create_test_documents(titles_data, max_documents=30)
        
        if doc_success:
            print("\nğŸ‰ ëª¨ë“  ì‘ì—… ì™„ë£Œ!")
        else:
            print("\nâš ï¸ ë¬¸ì„œ ìƒì„±ì€ ì‹¤íŒ¨í–ˆì§€ë§Œ ë°ì´í„° ìˆ˜ì§‘ì€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
    else:
        print("\nâœ… ë°ì´í„° ìˆ˜ì§‘ë§Œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main() 