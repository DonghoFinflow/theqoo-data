#!/usr/bin/env python3
"""
Streamlit OpenAI RAG Chat Application
text-embedding-3-smallì„ ì‚¬ìš©í•˜ì—¬ JSON íŒŒì¼ì„ Qdrantì— ì €ì¥í•˜ê³  Streamlitìœ¼ë¡œ ì±„íŒ…í•˜ëŠ” ì›¹ ì• í”Œë¦¬ì¼€ì´ì…˜
"""

import streamlit as st
import json
import os
import logging
from datetime import datetime
from openai_qdrant_storage import OpenAIQdrantStorage, load_documents_from_json
import requests
from dotenv import load_dotenv

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class StreamlitOpenAIRAGChat:
    def __init__(self, collection_name="theqoo_documents_openai"):
        """Streamlit OpenAI RAG ì±„íŒ… ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        self.collection_name = collection_name
        self.perplexity_api_key = os.getenv('PERPLEXITY_API_KEY')
        
        # OpenAI API í‚¤ í™•ì¸
        if not os.getenv('OPENAI_API_KEY'):
            st.error("âŒ OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            self.storage = None
            return
        
        # OpenAI Qdrant ìŠ¤í† ë¦¬ì§€ ì´ˆê¸°í™”
        try:
            self.storage = OpenAIQdrantStorage(collection_name=collection_name)
            st.success("âœ… OpenAI Qdrant ì—°ê²° ì„±ê³µ! (text-embedding-3-small)")
        except Exception as e:
            st.error(f"âŒ OpenAI Qdrant ì—°ê²° ì‹¤íŒ¨: {e}")
            self.storage = None
    
    def load_and_store_json(self, json_filename):
        """JSON íŒŒì¼ì„ ë¡œë“œí•˜ê³  OpenAI Qdrantì— ì €ì¥"""
        if not os.path.exists(json_filename):
            st.error(f"âŒ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {json_filename}")
            return False
        
        try:
            # JSON íŒŒì¼ì—ì„œ ë¬¸ì„œ ë¡œë“œ
            documents = load_documents_from_json(json_filename)
            if not documents:
                st.error("âŒ ë¬¸ì„œë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return False
            
            st.success(f"âœ… {len(documents)}ê°œ ë¬¸ì„œ ë¡œë“œ ì™„ë£Œ")
            
            # OpenAI Qdrantì— ì €ì¥
            with st.spinner("ğŸ’¾ OpenAI Qdrantì— ì €ì¥ ì¤‘..."):
                success = self.storage.store_documents(documents)
            
            if success:
                st.success("âœ… OpenAI Qdrant ì €ì¥ ì™„ë£Œ!")
                
                # ì»¬ë ‰ì…˜ ì •ë³´ ì¶œë ¥
                info = self.storage.get_collection_info()
                if info:
                    st.info(f"ğŸ“Š ì»¬ë ‰ì…˜ ë²¡í„° ìˆ˜: {info.vectors_count}")
                
                return True
            else:
                st.error("âŒ OpenAI Qdrant ì €ì¥ ì‹¤íŒ¨!")
                return False
                
        except Exception as e:
            st.error(f"âŒ íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
            return False
    
    def search_relevant_documents(self, query, limit=5):
        """ì¿¼ë¦¬ì™€ ê´€ë ¨ëœ ë¬¸ì„œ ê²€ìƒ‰"""
        if not self.storage:
            return []
        
        try:
            results = self.storage.search_similar_documents(query, limit=limit)
            return results
        except Exception as e:
            logger.error(f"ë¬¸ì„œ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []
    
    def create_context_from_documents(self, search_results):
        """ê²€ìƒ‰ ê²°ê³¼ë¡œë¶€í„° ì»¨í…ìŠ¤íŠ¸ ìƒì„±"""
        if not search_results:
            return ""
        
        context_parts = []
        for i, result in enumerate(search_results, 1):
            payload = result.payload
            content_preview = payload.get('content', '')[:300] if payload.get('content') else 'ë‚´ìš© ì—†ìŒ'
            analysis_preview = payload.get('analysis', '')[:500] if payload.get('analysis') else 'ë¶„ì„ ì—†ìŒ'
            
            context_parts.append(f"""
ë¬¸ì„œ {i} (ìœ ì‚¬ë„ ì ìˆ˜: {result.score:.3f}):
ì œëª©: {payload['title']}
ë§í¬: {payload['link']}
ì‘ì„±ì¼ì‹œ: {payload.get('post_datetime', 'N/A')}
ë‚´ìš©: {content_preview}...
ë¶„ì„: {analysis_preview}...
ëŒ“ê¸€ ìˆ˜: {payload.get('comments_count', 0)}ê°œ
---""")
        
        return "\n".join(context_parts)
    
    def generate_response_with_perplexity(self, query, context):
        """Perplexity APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì‘ë‹µ ìƒì„±"""
        if not self.perplexity_api_key:
            return "Perplexity API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
        
        try:
            prompt = f"""
ë‹¤ìŒì€ theqoo ê²Œì‹œíŒì˜ ë¬¸ì„œë“¤ì…ë‹ˆë‹¤. ì´ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”.

=== ì»¨í…ìŠ¤íŠ¸ ===
{context}

=== ì‚¬ìš©ì ì§ˆë¬¸ ===
{query}

ìœ„ì˜ ì»¨í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì¹œê·¼í•˜ê³  ìì—°ìŠ¤ëŸ½ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”. 
ë‹µë³€í•  ë•ŒëŠ” ê´€ë ¨ëœ ë¬¸ì„œì˜ ì •ë³´ë¥¼ ì–¸ê¸‰í•˜ê³ , í•„ìš”í•˜ë©´ ë§í¬ë„ ì œê³µí•´ì£¼ì„¸ìš”.
í•œêµ­ì–´ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”.
"""

            headers = {
                "Authorization": f"Bearer {self.perplexity_api_key}",
                "Content-Type": "application/json"
            }
            
            data = {
                "model": "sonar",
                "messages": [
                    {
                        "role": "system",
                        "content": "ë‹¹ì‹ ì€ theqoo ê²Œì‹œíŒì˜ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€í•˜ëŠ” ë„ìš°ë¯¸ì…ë‹ˆë‹¤. ì¹œê·¼í•˜ê³  ìì—°ìŠ¤ëŸ½ê²Œ ë‹µë³€í•´ì£¼ì„¸ìš”."
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ]
            }
            
            response = requests.post(
                "https://api.perplexity.ai/chat/completions",
                headers=headers,
                json=data,
                timeout=30
            )
            
            if response.status_code == 200:
                result = response.json()
                return result['choices'][0]['message']['content']
            else:
                return f"API í˜¸ì¶œ ì‹¤íŒ¨: {response.status_code}"
                
        except Exception as e:
            logger.error(f"Perplexity API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            return f"ì‘ë‹µ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"
    
    def chat(self, query, max_documents=5):
        """ì±„íŒ… ê¸°ëŠ¥"""
        if not self.storage:
            return "OpenAI Qdrant ì—°ê²°ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.", []
        
        # ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰
        search_results = self.search_relevant_documents(query, limit=max_documents)
        
        if not search_results:
            return "ì£„ì†¡í•©ë‹ˆë‹¤. ê´€ë ¨ëœ ë¬¸ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", []
        
        # ì»¨í…ìŠ¤íŠ¸ ìƒì„±
        context = self.create_context_from_documents(search_results)
        
        # ì‘ë‹µ ìƒì„±
        response = self.generate_response_with_perplexity(query, context)
        
        return response, search_results
    
    def check_collection_has_data(self):
        """ì»¬ë ‰ì…˜ì— ë°ì´í„°ê°€ ìˆëŠ”ì§€ ì•ˆì „í•˜ê²Œ í™•ì¸"""
        if not self.storage:
            return False, 0
        
        try:
            # ì»¬ë ‰ì…˜ ì •ë³´ í™•ì¸
            info = self.storage.get_collection_info()
            if not info:
                logger.error("ì»¬ë ‰ì…˜ ì •ë³´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return False, 0
            
            # points_count í™•ì¸ (vectors_countê°€ Noneì´ì–´ë„ points_countë¡œ íŒë‹¨)
            if hasattr(info, 'points_count') and info.points_count is not None and info.points_count > 0:
                logger.info(f"ì»¬ë ‰ì…˜ì— {info.points_count}ê°œì˜ í¬ì¸íŠ¸ê°€ ìˆìŠµë‹ˆë‹¤.")
                return True, info.points_count
            
            # vectors_count í™•ì¸ (ë°±ì—…)
            if hasattr(info, 'vectors_count') and info.vectors_count is not None and info.vectors_count > 0:
                logger.info(f"vectors_countë¡œ íŒë‹¨: {info.vectors_count}ê°œ")
                return True, info.vectors_count
            
            # ì‹¤ì œ ë°ì´í„°ê°€ ìˆëŠ”ì§€ í™•ì¸ (scrollë¡œ ì‹¤ì œ í¬ì¸íŠ¸ ì¡°íšŒ)
            try:
                points = self.storage.client.scroll(
                    collection_name=self.collection_name,
                    limit=1,
                    with_payload=False,
                    with_vectors=False
                )
                actual_points = len(points[0]) if points and len(points) > 0 else 0
                
                if actual_points > 0:
                    logger.info(f"ì»¬ë ‰ì…˜ì— {actual_points}ê°œì˜ ì‹¤ì œ í¬ì¸íŠ¸ê°€ ìˆìŠµë‹ˆë‹¤.")
                    return True, actual_points
                else:
                    logger.warning("ì»¬ë ‰ì…˜ì— ì‹¤ì œ í¬ì¸íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    return False, 0
                    
            except Exception as scroll_error:
                logger.error(f"í¬ì¸íŠ¸ ì¡°íšŒ ì‹¤íŒ¨: {scroll_error}")
                return False, 0
                    
        except Exception as e:
            logger.error(f"ì»¬ë ‰ì…˜ ë°ì´í„° í™•ì¸ ì‹¤íŒ¨: {e}")
            return False, 0

def main():
    """Streamlit ë©”ì¸ ì•±"""
    st.set_page_config(
        page_title="OpenAI RAG Chat System",
        page_icon="ğŸ¤–",
        layout="wide"
    )
    
    st.title("ğŸ¤– OpenAI RAG Chat System")
    st.markdown("text-embedding-3-smallì„ ì‚¬ìš©í•œ theqoo ê²Œì‹œíŒ ë°ì´í„° ê¸°ë°˜ ì±„íŒ… ì‹œìŠ¤í…œ")
    
    # ì‚¬ì´ë“œë°” ì„¤ì •
    with st.sidebar:
        st.header("âš™ï¸ ì„¤ì •")
        
        # ì»¬ë ‰ì…˜ ì„ íƒ
        collection_name = st.selectbox(
            "ì»¬ë ‰ì…˜ ì„ íƒ",
            ["theqoo_documents_openai", "theqoo_documents_openai_v2"],
            index=0
        )
        
        # JSON íŒŒì¼ ì„ íƒ
        json_files = []
        for file in os.listdir('.'):
            if file.endswith('.json') and ('hot_pages' in file or 'test_documents' in file):
                json_files.append(file)
        
        if json_files:
            selected_file = st.selectbox(
                "JSON íŒŒì¼ ì„ íƒ",
                json_files,
                index=0 if 'test_documents_hot_pages_2025-07-21.json' in json_files else 0
            )
            
            if st.button("ğŸ“ OpenAI Qdrantì— ë°ì´í„° ë¡œë“œ"):
                rag_system = StreamlitOpenAIRAGChat(collection_name=collection_name)
                success = rag_system.load_and_store_json(selected_file)
                
                if success:
                    st.session_state.rag_system = rag_system
                    st.session_state.data_loaded = True
            
            # ê¸°ì¡´ ë°ì´í„°ê°€ ìˆëŠ”ì§€ í™•ì¸í•˜ê³  ë°”ë¡œ ê²€ìƒ‰ ê°€ëŠ¥í•˜ë„ë¡ ì„¤ì •
            if st.button("ğŸ” ê¸°ì¡´ ë°ì´í„°ë¡œ ê²€ìƒ‰ ì‹œì‘"):
                st.info(f"ğŸ” ì»¬ë ‰ì…˜ '{collection_name}'ì—ì„œ ë°ì´í„° í™•ì¸ ì¤‘...")
                rag_system = StreamlitOpenAIRAGChat(collection_name=collection_name)
                if rag_system.storage:
                    # ì•ˆì „í•œ ì»¬ë ‰ì…˜ ë°ì´í„° í™•ì¸
                    has_data, vector_count = rag_system.check_collection_has_data()
                    if has_data:
                        st.session_state.rag_system = rag_system
                        st.session_state.data_loaded = True
                        st.success(f"âœ… ê¸°ì¡´ ë°ì´í„°ë¡œ ê²€ìƒ‰ ì¤€ë¹„ ì™„ë£Œ! (ë²¡í„° ìˆ˜: {vector_count}ê°œ)")
                    else:
                        st.error(f"âŒ ì»¬ë ‰ì…˜ '{collection_name}'ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ë°ì´í„°ë¥¼ ë¡œë“œí•´ì£¼ì„¸ìš”.")
                else:
                    st.error("âŒ OpenAI Qdrant ì—°ê²°ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        else:
            st.warning("ì‚¬ìš© ê°€ëŠ¥í•œ JSON íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        
        # ê²€ìƒ‰ ì„¤ì •
        st.header("ğŸ” ê²€ìƒ‰ ì„¤ì •")
        max_documents = st.slider("ìµœëŒ€ ê²€ìƒ‰ ë¬¸ì„œ ìˆ˜", 1, 10, 5)
        
        # API í‚¤ ìƒíƒœ í™•ì¸
        st.header("ğŸ”‘ API ìƒíƒœ")
        if os.getenv('OPENAI_API_KEY'):
            st.success("âœ… OpenAI API í‚¤ ì„¤ì •ë¨")
        else:
            st.error("âŒ OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•ŠìŒ")
            
        if os.getenv('PERPLEXITY_API_KEY'):
            st.success("âœ… Perplexity API í‚¤ ì„¤ì •ë¨")
        else:
            st.error("âŒ Perplexity API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•ŠìŒ")
    
    # ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
    if 'messages' not in st.session_state:
        st.session_state.messages = []
    
    if 'data_loaded' not in st.session_state:
        st.session_state.data_loaded = False
    
    if 'rag_system' not in st.session_state:
        st.session_state.rag_system = None
    
    # í™˜ì˜ ë©”ì‹œì§€
    if not st.session_state.messages:
        st.session_state.messages.append({
            "role": "assistant",
            "content": "ì•ˆë…•í•˜ì„¸ìš”! text-embedding-3-smallì„ ì‚¬ìš©í•œ RAG ì±„íŒ… ì‹œìŠ¤í…œì…ë‹ˆë‹¤. ë¨¼ì € ì‚¬ì´ë“œë°”ì—ì„œ 'ê¸°ì¡´ ë°ì´í„°ë¡œ ê²€ìƒ‰ ì‹œì‘' ë²„íŠ¼ì„ í´ë¦­í•˜ê±°ë‚˜ JSON íŒŒì¼ì„ ë¡œë“œí•´ì£¼ì„¸ìš”."
        })
    
    # ì±„íŒ… íˆìŠ¤í† ë¦¬ í‘œì‹œ
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
    
    # ì‚¬ìš©ì ì…ë ¥
    if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”...", key="chat_input"):
        # ì‚¬ìš©ì ë©”ì‹œì§€ ì¶”ê°€
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)
        
        # ë°ì´í„°ê°€ ë¡œë“œë˜ì§€ ì•Šì•˜ìœ¼ë©´ ì•ˆë‚´
        if not st.session_state.data_loaded or st.session_state.rag_system is None:
            with st.chat_message("assistant"):
                st.error("ë¨¼ì € ì‚¬ì´ë“œë°”ì—ì„œ 'ê¸°ì¡´ ë°ì´í„°ë¡œ ê²€ìƒ‰ ì‹œì‘' ë²„íŠ¼ì„ í´ë¦­í•˜ê±°ë‚˜ JSON íŒŒì¼ì„ ë¡œë“œí•´ì£¼ì„¸ìš”.")
            st.session_state.messages.append({
                "role": "assistant",
                "content": "ë¨¼ì € ì‚¬ì´ë“œë°”ì—ì„œ 'ê¸°ì¡´ ë°ì´í„°ë¡œ ê²€ìƒ‰ ì‹œì‘' ë²„íŠ¼ì„ í´ë¦­í•˜ê±°ë‚˜ JSON íŒŒì¼ì„ ë¡œë“œí•´ì£¼ì„¸ìš”."
            })
        else:
            # ì‘ë‹µ ìƒì„±
            with st.chat_message("assistant"):
                with st.spinner("ğŸ¤– text-embedding-3-smallìœ¼ë¡œ ì‘ë‹µ ìƒì„± ì¤‘..."):
                    response, search_results = st.session_state.rag_system.chat(prompt, max_documents)
                    st.markdown(response)
                
                # ê²€ìƒ‰ ê²°ê³¼ í‘œì‹œ (ì ‘ì„ ìˆ˜ ìˆëŠ” ì„¹ì…˜)
                if search_results:
                    with st.expander(f"ğŸ” ê´€ë ¨ ë¬¸ì„œ ({len(search_results)}ê°œ) - text-embedding-3-small"):
                        for i, result in enumerate(search_results, 1):
                            payload = result.payload
                            st.markdown(f"""
                            **ë¬¸ì„œ {i}** (ìœ ì‚¬ë„: {result.score:.3f})
                            - **ì œëª©**: {payload['title']}
                            - **ë§í¬**: {payload['link']}
                            - **ì‘ì„±ì¼ì‹œ**: {payload.get('post_datetime', 'N/A')}
                            - **ëŒ“ê¸€ ìˆ˜**: {payload.get('comments_count', 0)}ê°œ
                            - **ì„ë² ë”© ëª¨ë¸**: {payload.get('embedding_model', 'text-embedding-3-small')}
                            """)
                            if payload.get('content'):
                                st.markdown(f"**ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°**: {payload.get('content', '')[:200]}...")
                            if payload.get('analysis'):
                                st.markdown(f"**ë¶„ì„**: {payload['analysis'][:300]}...")
                            if payload.get('comments'):
                                comments_preview = ", ".join(payload['comments'][:3])
                                if len(comments_preview) > 200:
                                    comments_preview = comments_preview[:200] + "..."
                                st.markdown(f"**ëŒ“ê¸€ ë¯¸ë¦¬ë³´ê¸°**: {comments_preview}")
                            st.divider()
            
            # ì–´ì‹œìŠ¤í„´íŠ¸ ë©”ì‹œì§€ ì¶”ê°€
            st.session_state.messages.append({"role": "assistant", "content": response})
    
    # ì±„íŒ… íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™” ë²„íŠ¼
    if st.session_state.messages:
        if st.button("ğŸ—‘ï¸ ì±„íŒ… íˆìŠ¤í† ë¦¬ ì´ˆê¸°í™”"):
            st.session_state.messages = []
            st.session_state.data_loaded = False
            st.session_state.rag_system = None
            st.rerun()

if __name__ == "__main__":
    main() 